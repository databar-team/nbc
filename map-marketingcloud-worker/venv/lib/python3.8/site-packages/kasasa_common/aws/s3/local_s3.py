from __future__ import annotations
import io
import os
import shutil
import sys
from os import path as op
from typing import Generator, TextIO, BinaryIO, Union

from kasasa_common.aws.s3.base_s3 import BaseS3Helper, BucketNotAvailable
from kasasa_common.util.file_system_helpers import makedirs_unless_exist, rmtree_if_exists
from kasasa_common import logger


class LocalS3(BaseS3Helper):
    """
    Implementation of s3 helper
    using local filesystem instead of real s3 bucket.
    It is expected to behave the same way as `RealS3`
    (although inconsistencies are possible).
    """

    def __init__(self, bucket: str):
        super(LocalS3, self).__init__(bucket)

        # try in current directory
        # then in app's base directory
        # the latter one is actually a fallback which might not work correctly

        # __file__ won't work when used from interactive python shell
        # so for it fall back to CWD
        base = getattr(sys.modules['__main__'], '__file__', '.')
        for path in [
            bucket,
            op.join(base, bucket),
        ]:
            if op.exists(path) and op.isdir(path):
                self.path = op.abspath(path)
                break
        else:
            raise BucketNotAvailable('No such local bucket: {}'.format(bucket))

    def list(self, prefix: str = None, only_after: str = None) -> Generator:
        if prefix:
            base = op.join(self.path, prefix.strip('/'))
            if not op.isdir(base):
                # Nothing to iterate over
                # (whether it is a file or missing)
                return
        else:
            base = self.path

        # we want to yield paths within the bucket,
        # hence cut based on our basepath
        cut = len(self.path) + 1

        for dirpath, dirnames, filenames in os.walk(base):
            for name in filenames:
                full = op.join(dirpath, name)
                # convert from full/relative path to key
                key = full[cut:]
                if only_after:
                    if key == only_after:
                        # start yielding from next key
                        only_after = None
                else:
                    yield key

    def list_prefix(self, prefix: str) -> Generator:
        src = op.join(self.path, prefix)
        logger.info('src: %s', src)

        if not op.exists(self.path):
            raise ValueError('Bucket {!r} has no object {!r}'.format(
                self.bucket, prefix))
        for fname in os.listdir(src):
            yield fname

    def list_dirs(self, prefix: str = None) -> Generator:
        base = self.path
        if prefix:
            base = op.join(base, prefix.strip('/'))
            if not op.isdir(base):
                # nothing to yield
                return

        cut = len(self.path) + 1
        for name in os.listdir(base):
            full = op.join(base, name)
            if op.isdir(full):
                yield full[cut:] + '/'

    def _exists(self, key: str) -> bool:
        path = op.join(self.path, key)
        return op.exists(path) and not op.isdir(path)

    def _download(self, key: str, fullpath: str):
        src = op.join(self.path, key)
        if not op.exists(src):
            raise ValueError('Bucket {!r} has no object {!r}'.format(
                self.bucket, key))

        shutil.copyfile(src, fullpath)

    def _open_r(self, key: str, binary: bool) -> Union[BinaryIO, TextIO]:
        return io.open(op.join(self.path, key), 'rb' if binary else 'r')

    def _upload(self, localobj: str, name: str = None, overwrite: bool = False):
        subdir = op.dirname(name)
        if subdir:
            makedirs_unless_exist(op.join(self.path, subdir))

        src = localobj
        tgt = op.join(self.path, name)

        if overwrite:
            rmtree_if_exists(tgt)
        elif op.exists(tgt):
            raise ValueError('Already exists, won\'t overwrite')

        if op.isdir(localobj):
            shutil.copytree(src, tgt)
        else:
            shutil.copyfile(src, tgt)

    def _upload_with_args(self, localobj: str, name: str = None, overwrite: bool = False, **kwargs):
        self._upload(localobj, name, overwrite)

    def _upload_fileobj(self, localobj: Union[TextIO, BinaryIO], name: str = None, overwrite: bool = False):
        tgt = op.join(self.path, name)

        if overwrite:
            rmtree_if_exists(tgt)
        elif op.exists(tgt):
            raise ValueError('Already exists, won\'t overwrite')

        # make sure all super directories exist
        makedirs_unless_exist(op.dirname(tgt))
        with open(tgt, 'wb') as tgtfile:
            while True:
                chunk = localobj.read(1024)
                if not chunk:
                    break
                tgtfile.write(chunk)

    def _upload_fileobj_with_args(self, localobj: Union[TextIO, BinaryIO], name: str = None, overwrite: bool = False,
                                  **kwargs):
        self._upload_fileobj(localobj, name, overwrite)

    def _remove(self, key: str, recursive: bool = False):
        path = op.join(self.path, key)
        if not op.exists(path):
            raise ValueError('No such object: {}'.format(key))
        if recursive:
            shutil.rmtree(path)
        else:
            os.remove(path)
        # make sure any empty superdirs are removed
        # we cannot use removedirs here because it could remove `path` itself
        # list filtering is to avoid [''] as a result
        prefixdirs = [p for p in op.dirname(key).split(op.sep) if p]
        while prefixdirs:
            try:
                os.rmdir(op.join(self.path, *prefixdirs))
            except Exception:
                # probably non-empty
                break

    def _rename(self, src: str, dst: str):
        srcpath = op.join(self.path, src)
        dstpath = op.join(self.path, dst)

        # it will also make any required dirs and prune any old&empty ones
        os.renames(srcpath, dstpath)

    def _copy_from(self, src_bucket: Union[str, LocalS3], src_key: str, dst_key: str):
        """
        :param src_bucket: either bucket of LocalS3 object.
            This is for optimization only.
        """
        # TODO: Move this if/else to copy_from in the parent class and pass the object down the chain or just remove it
        if not isinstance(src_bucket, LocalS3):
            src_s3 = LocalS3(src_bucket)
        else:
            src_s3 = src_bucket
        srcpath = op.join(src_s3.path, src_key)
        dstpath = op.join(self.path, dst_key)

        basedir = op.dirname(dstpath)  # not the same as self.path
        if not op.isdir(basedir):
            os.makedirs(basedir)
        shutil.copyfile(srcpath, dstpath)

    def _copy_to(self, src_key: str, dst_s3: BaseS3Helper, dst_key: str):
        return dst_s3._copy_from(self, src_key, dst_key)

    def _copy_to_with_args(self, src_key: str, dst_s3: BaseS3Helper, dst_key: str, **kwargs):
        return dst_s3._copy_from(self, src_key, dst_key)

    def _copy_from_with_args(self, src_key: str, dst_s3: BaseS3Helper, dst_key: str, **kwargs):
        return dst_s3._copy_from(self, src_key, dst_key)

    def __repr__(self):
        return '<LocalS3 bucket={bucket} path={path}>'.format(
            bucket=self.bucket,
            path=self.path,
        )