import json
import warnings
from urllib import parse

from kasasa_common.aws.s3.base_s3 import BucketNotAvailable, BaseS3Helper
from kasasa_common.aws.s3.real_s3 import RealS3
from kasasa_common.aws.s3.local_s3 import LocalS3
from kasasa_common import logger


def get_s3(bucket, force_real=False, force_local=False, session=None, validate=False) -> BaseS3Helper:
    """
    Return s3 helper class instance for given bucket id.
    """
    if all([force_real, force_local]):
        raise ValueError('Only one of (force_real, force_local) is allowed')

    if force_real:
        return RealS3(bucket, session)
    elif force_local:
        return LocalS3(bucket)

    # is requested bucket available locally?
    try:
        s3 = LocalS3(bucket)
        logger.debug('Using local directory %s instead of S3 bucket %s', s3.path, bucket)
    except BucketNotAvailable:
        # not available locally - try real s3 (might raise)
        s3 = RealS3(bucket, session, validate)
        logger.debug('Using actual AWS S3 instance for bucket %s', bucket)
    return s3


def get_secrets(bucket, key):
    """
    This helper function provides cached access to secrets file.
    File is decoded from JSON.
    Upon first access it is cached in memory.

    Secrets file is a JSON-encoded text file
    containing passwords and other sensitive information
    which should not be stored in environment variables for some reason.
    """
    warnings.warn("Use Vault for secrets", DeprecationWarning)
    global _secrets
    if not _secrets:
        logger.debug('Obtaining secrets from S3 bucket %s, key %s...', bucket, key)
        s3 = get_s3(bucket)
        obj = s3.open_r(key)
        _secrets = json.load(obj)
    else:
        logger.debug('Using pre-fetched secrets...')
    return _secrets


def get_bucket_and_key(s3_path):
    """
    GIVEN s3_path in the form s3://bucket/path/to/object
    WHEN get_bucket_and_key(s3_path)
    THEN return (bucket, /path/to/object)

    :param s3_path: The path to get the bucket and key from.
    :return: (bucket, path/to/object)
    """
    S3_SCHEME_NAME = "s3"
    parsed = parse.urlparse(s3_path)
    if parsed.scheme != S3_SCHEME_NAME:
        raise ValueError("{path} is not a valid s3 path".format(path=s3_path))
    bucket = parsed.netloc
    key = parsed.path
    return bucket, key
